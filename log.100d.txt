Iteration 0, loss=0.6930614709854126
{'defendant': 0.31391937, 'acronym': 0.31956685, 'saxony': 0.32547134, 'watch': 0.33391035, 'hussein': 0.34466395, 'liked': 0.3528119, 'rock': 0.35997775, 'strict': 0.378354, 'imperfect': 0.37954193, 'eight': 1.0000001}
Iteration 100, loss=0.6926762461662292
Iteration 200, loss=0.6907530426979065
Iteration 300, loss=0.689892053604126
Iteration 400, loss=0.6975107192993164
Iteration 500, loss=0.6793779134750366
Iteration 600, loss=0.6734567880630493
Iteration 700, loss=0.6712284088134766
Iteration 800, loss=0.6756799221038818
Iteration 900, loss=0.7070267796516418
Iteration 1000, loss=0.6868252158164978
Iteration 1100, loss=0.687457799911499
Iteration 1200, loss=0.6911949515342712
Iteration 1300, loss=0.6887220740318298
Iteration 1400, loss=0.7043663859367371
Iteration 1500, loss=0.681961178779602
Iteration 1600, loss=0.7055506706237793
Iteration 1700, loss=0.7057968974113464
Iteration 1800, loss=0.7096203565597534
Iteration 1900, loss=0.7046681642532349
Iteration 2000, loss=0.684991180896759
Iteration 2100, loss=0.7113454937934875
Iteration 2200, loss=0.714099645614624
Iteration 2300, loss=0.6808810830116272
Iteration 2400, loss=0.685502290725708
Iteration 2500, loss=0.691115140914917
Iteration 2600, loss=0.6947378516197205
Iteration 2700, loss=0.690316915512085
Iteration 2800, loss=0.6871575713157654
Iteration 2900, loss=0.6942217946052551
Iteration 3000, loss=0.6906322240829468
Iteration 3100, loss=0.6942653059959412
Iteration 3200, loss=0.6984215974807739
Iteration 3300, loss=0.6928151845932007
Iteration 3400, loss=0.6856873035430908
Iteration 3500, loss=0.7058809995651245
Iteration 3600, loss=0.7034185528755188
Iteration 3700, loss=0.686212956905365
Iteration 3800, loss=0.7075731158256531
Iteration 3900, loss=0.682354748249054
Iteration 4000, loss=0.7051500678062439
Iteration 4100, loss=0.6821957230567932
Iteration 4200, loss=0.6828731894493103
Iteration 4300, loss=0.6882055401802063
Iteration 4400, loss=0.6851133704185486
Iteration 4500, loss=0.6779008507728577
Iteration 4600, loss=0.6723596453666687
Iteration 4700, loss=0.6836062073707581
Iteration 4800, loss=0.6807112693786621
Iteration 4900, loss=0.704097330570221
Iteration 5000, loss=0.6758584976196289
Iteration 5100, loss=0.6852695941925049
Iteration 5200, loss=0.7017285823822021
Iteration 5300, loss=0.7052417397499084
Iteration 5400, loss=0.6870810389518738
Iteration 5500, loss=0.6979185342788696
Iteration 5600, loss=0.6931880712509155
Iteration 5700, loss=0.6902581453323364
Iteration 5800, loss=0.704115092754364
Iteration 5900, loss=0.6925299167633057
Iteration 6000, loss=0.7147323489189148
Iteration 6100, loss=0.6669880151748657
Iteration 6200, loss=0.6632075309753418
Iteration 6300, loss=0.6652665138244629
Iteration 6400, loss=0.6669737100601196
Iteration 6500, loss=0.681651771068573
Iteration 6600, loss=0.7021714448928833
Iteration 6700, loss=0.6717312932014465
Iteration 6800, loss=0.7065723538398743
Iteration 6900, loss=0.6759534478187561
Iteration 7000, loss=0.6938414573669434
Iteration 7100, loss=0.6965768337249756
Iteration 7200, loss=0.6885137557983398
Iteration 7300, loss=0.7152528762817383
Iteration 7400, loss=0.7149446606636047
Iteration 7500, loss=0.6859652400016785
Iteration 7600, loss=0.6992323398590088
Iteration 7700, loss=0.6809571981430054
Iteration 7800, loss=0.6748029589653015
Iteration 7900, loss=0.6973099112510681
Iteration 8000, loss=0.6815868020057678
Iteration 8100, loss=0.49815458059310913
Iteration 8200, loss=0.6872425675392151
Iteration 8300, loss=0.7327166795730591
Iteration 8400, loss=0.7101665139198303
Iteration 8500, loss=0.7151589393615723
Iteration 8600, loss=0.6684838533401489
Iteration 8700, loss=0.7242594957351685
Iteration 8800, loss=0.7095038890838623
Iteration 8900, loss=0.6888312101364136
Iteration 9000, loss=0.695638120174408
Iteration 9100, loss=0.7236915230751038
Iteration 9200, loss=0.7064857482910156
Iteration 9300, loss=0.721649169921875
Iteration 9400, loss=0.7028754949569702
Iteration 9500, loss=0.6786201000213623
Iteration 9600, loss=0.7006065249443054
Iteration 9700, loss=0.6925675272941589
Iteration 9800, loss=0.6939859390258789
Iteration 9900, loss=0.6957131624221802
Iteration 10000, loss=0.677151620388031
{'inches': 0.5181022, 'kuwait': 0.5230149, 'jr': 0.53309846, 'one': 0.5402043, 'christopher': 0.5668376, 'capacity': 0.6242003, 'minutes': 0.63024974, 'winners': 0.63703537, 'ferdinand': 0.63766533, 'eight': 1.0}
Iteration 10100, loss=0.6782339215278625
Iteration 10200, loss=0.7048119902610779
Iteration 10300, loss=0.6312621831893921
Iteration 10400, loss=0.47709667682647705
Iteration 10500, loss=0.6981223821640015
Iteration 10600, loss=0.6915672421455383
Iteration 10700, loss=0.7054805159568787
Iteration 10800, loss=0.7134161591529846
Iteration 10900, loss=0.6643159985542297
Iteration 11000, loss=0.6882704496383667
Iteration 11100, loss=0.6691413521766663
Iteration 11200, loss=0.6897949576377869
Iteration 11300, loss=0.6770511269569397
Iteration 11400, loss=0.7262020111083984
Iteration 11500, loss=0.6937962174415588
Iteration 11600, loss=0.6881358027458191
Iteration 11700, loss=0.647670328617096
Iteration 11800, loss=0.6797895431518555
Iteration 11900, loss=0.6278457641601562
Iteration 12000, loss=0.692871630191803
Iteration 12100, loss=0.6858655214309692
Iteration 12200, loss=0.6854761838912964
Iteration 12300, loss=0.6712422966957092
Iteration 12400, loss=0.7092434167861938
Iteration 12500, loss=0.7140647172927856
Iteration 12600, loss=0.5752967000007629
Iteration 12700, loss=0.6835444569587708
Iteration 12800, loss=0.6671540141105652
Iteration 12900, loss=0.6611634492874146
Iteration 13000, loss=0.6614573001861572
Iteration 13100, loss=0.746769368648529
Iteration 13200, loss=0.6663457155227661
Iteration 13300, loss=0.634635329246521
Iteration 13400, loss=0.6620067358016968
Iteration 13500, loss=0.6629853248596191
Iteration 13600, loss=0.7165688276290894
Iteration 13700, loss=0.48367294669151306
Iteration 13800, loss=0.645729660987854
Iteration 13900, loss=0.5361859798431396
Iteration 14000, loss=0.6995528340339661
Iteration 14100, loss=0.66950923204422
Iteration 14200, loss=0.6860240697860718
Iteration 14300, loss=0.7475950121879578
Iteration 14400, loss=0.6980039477348328
Iteration 14500, loss=0.7021178007125854
Iteration 14600, loss=0.6830970048904419
Iteration 14700, loss=0.6344112753868103
Iteration 14800, loss=0.6782859563827515
Iteration 14900, loss=0.6829727292060852
Iteration 15000, loss=0.40823477506637573
Iteration 15100, loss=0.6627273559570312
Iteration 15200, loss=0.6329786777496338
Iteration 15300, loss=0.6623014807701111
Iteration 15400, loss=0.6777516007423401
Iteration 15500, loss=0.7500108480453491
Iteration 15600, loss=0.6656956672668457
Iteration 15700, loss=0.6939718723297119
Iteration 15800, loss=0.6973258256912231
Iteration 15900, loss=0.6797463297843933
Iteration 16000, loss=0.6962679624557495
Iteration 16100, loss=0.7257097959518433
Iteration 16200, loss=0.7285826206207275
Iteration 16300, loss=0.6313336491584778
Iteration 16400, loss=0.7011376619338989
Iteration 16500, loss=0.7577484846115112
Iteration 16600, loss=0.6796537041664124
Iteration 16700, loss=0.6591857671737671
Iteration 16800, loss=0.6986960172653198
Iteration 16900, loss=0.6862952709197998
Iteration 17000, loss=0.6438663005828857
Iteration 17100, loss=0.6443993449211121
Iteration 17200, loss=0.7134246826171875
Iteration 17300, loss=0.6313482522964478
Iteration 17400, loss=0.6448473334312439
Iteration 17500, loss=0.652619481086731
Iteration 17600, loss=0.6248812079429626
Iteration 17700, loss=0.6759018898010254
Iteration 17800, loss=0.7712661027908325
Iteration 17900, loss=0.731623113155365
Iteration 18000, loss=0.8375717997550964
Iteration 18100, loss=0.6455110311508179
Iteration 18200, loss=0.8551715612411499
Iteration 18300, loss=0.6329914927482605
Iteration 18400, loss=0.7024843096733093
Iteration 18500, loss=0.6627140641212463
Iteration 18600, loss=0.6011877059936523
Iteration 18700, loss=0.6811560988426208
Iteration 18800, loss=0.7374768853187561
Iteration 18900, loss=0.6615883708000183
Iteration 19000, loss=0.596798837184906
Iteration 19100, loss=0.7600382566452026
Iteration 19200, loss=0.6253048777580261
Iteration 19300, loss=0.6780322790145874
Iteration 19400, loss=0.6590492129325867
Iteration 19500, loss=0.6381967067718506
Iteration 19600, loss=0.6771725416183472
Iteration 19700, loss=0.7074204087257385
Iteration 19800, loss=0.639193594455719
Iteration 19900, loss=0.6605391502380371
Iteration 20000, loss=0.6584140062332153
{'of': 0.64521164, 'commission': 0.6519958, 'winners': 0.65604943, 'and': 0.65918106, 'blend': 0.6624178, 'sciences': 0.66505414, 'nine': 0.6941528, 'one': 0.7018645, 'constantinople': 0.72556686, 'eight': 0.9999999}
Iteration 20100, loss=0.6673528552055359
Iteration 20200, loss=0.5510231256484985
Iteration 20300, loss=0.7988852262496948
Iteration 20400, loss=0.7637017965316772
Iteration 20500, loss=0.004789938218891621
Iteration 20600, loss=0.6143695712089539
Iteration 20700, loss=0.6684151887893677
Iteration 20800, loss=0.603595495223999
Iteration 20900, loss=0.7616564035415649
Iteration 21000, loss=0.6117831468582153
Iteration 21100, loss=0.6428717374801636
Iteration 21200, loss=0.590336799621582
Iteration 21300, loss=0.7637002468109131
Iteration 21400, loss=0.5087055563926697
Iteration 21500, loss=0.8015028238296509
Iteration 21600, loss=0.6251531839370728
Iteration 21700, loss=0.786095380783081
Iteration 21800, loss=0.6014007329940796
Iteration 21900, loss=0.6305124759674072
Iteration 22000, loss=1.0234439373016357
Iteration 22100, loss=0.5754069089889526
Iteration 22200, loss=0.38790223002433777
Iteration 22300, loss=0.4204692542552948
Iteration 22400, loss=0.6260605454444885
Iteration 22500, loss=0.39358484745025635
Iteration 22600, loss=0.5623879432678223
Iteration 22700, loss=0.6628490090370178
Iteration 22800, loss=0.6755781769752502
Iteration 22900, loss=0.7520662546157837
Iteration 23000, loss=0.6485163569450378
Iteration 23100, loss=0.8464838266372681
Iteration 23200, loss=0.8030820488929749
Iteration 23300, loss=0.7337968349456787
Iteration 23400, loss=0.8505082130432129
Iteration 23500, loss=0.7003588080406189
Iteration 23600, loss=0.6474364399909973
Iteration 23700, loss=0.7612782120704651
Iteration 23800, loss=0.48913347721099854
Iteration 23900, loss=0.6404364705085754
Iteration 24000, loss=0.6095660924911499
Iteration 24100, loss=0.6162146925926208
Iteration 24200, loss=0.6300036311149597
Iteration 24300, loss=0.6431192755699158
Iteration 24400, loss=0.1881672739982605
Iteration 24500, loss=0.6954486966133118
Iteration 24600, loss=0.6373278498649597
Iteration 24700, loss=0.6523407101631165
Iteration 24800, loss=0.5550159811973572
Iteration 24900, loss=0.5469169616699219
Iteration 25000, loss=0.8425638675689697
Iteration 25100, loss=0.6039252877235413
Iteration 25200, loss=0.7876923084259033
Iteration 25300, loss=0.7354299426078796
Iteration 25400, loss=0.48848918080329895
Iteration 25500, loss=0.830654501914978
Iteration 25600, loss=0.6498595476150513
Iteration 25700, loss=0.6431109309196472
Iteration 25800, loss=0.5814807415008545
Iteration 25900, loss=0.29671427607536316
Iteration 26000, loss=0.6155949831008911
Iteration 26100, loss=0.642509937286377
Iteration 26200, loss=0.6188758611679077
Iteration 26300, loss=0.8052586913108826
Iteration 26400, loss=0.6967813372612
Iteration 26500, loss=0.7320292592048645
Iteration 26600, loss=0.8180569410324097
Iteration 26700, loss=0.610546886920929
Iteration 26800, loss=0.6293843388557434
Iteration 26900, loss=0.7973618507385254
Iteration 27000, loss=0.5372271537780762
Iteration 27100, loss=0.6775486469268799
Iteration 27200, loss=0.8659507632255554
Iteration 27300, loss=0.4280231297016144
Iteration 27400, loss=0.6007424592971802
Iteration 27500, loss=0.7034807205200195
Iteration 27600, loss=0.7352291345596313
Iteration 27700, loss=0.6168884634971619
Iteration 27800, loss=0.33852431178092957
Iteration 27900, loss=0.2761955261230469
Iteration 28000, loss=0.5950083136558533
Iteration 28100, loss=0.6440622210502625
Iteration 28200, loss=0.5637227892875671
Iteration 28300, loss=0.88564133644104
Iteration 28400, loss=0.7854042649269104
Iteration 28500, loss=0.7964332699775696
Iteration 28600, loss=0.5815730094909668
Iteration 28700, loss=0.6271787285804749
Iteration 28800, loss=0.8097761273384094
Iteration 28900, loss=0.6803905367851257
Iteration 29000, loss=0.7963657379150391
Iteration 29100, loss=0.5801244974136353
Iteration 29200, loss=0.7163203954696655
Iteration 29300, loss=0.7287163734436035
Iteration 29400, loss=0.6362454891204834
Iteration 29500, loss=0.7493366003036499
Iteration 29600, loss=0.6927505731582642
Iteration 29700, loss=0.43471813201904297
Iteration 29800, loss=0.6884077191352844
Iteration 29900, loss=0.6416608691215515
Iteration 30000, loss=0.5054922699928284
{'constantinople': 0.6790685, 'one': 0.6841921, 'blue': 0.68422216, 'grand': 0.6846384, 'four': 0.68718207, 'five': 0.6952958, 'nine': 0.69786316, 'circa': 0.78097546, 'miles': 0.7815803, 'eight': 1.0}
Iteration 30100, loss=0.7117406129837036
Iteration 30200, loss=0.7405941486358643
Iteration 30300, loss=0.35217928886413574
Iteration 30400, loss=0.22935271263122559
Iteration 30500, loss=0.7655637860298157
Iteration 30600, loss=0.652923583984375
Iteration 30700, loss=0.4638226330280304
Iteration 30800, loss=0.7309603691101074
Iteration 30900, loss=0.6259782910346985
Iteration 31000, loss=0.45501041412353516
Iteration 31100, loss=0.7769299745559692
Iteration 31200, loss=0.7115025520324707
Iteration 31300, loss=0.7496641874313354
Iteration 31400, loss=0.6196574568748474
Iteration 31500, loss=0.7610431909561157
Iteration 31600, loss=0.7537297010421753
Iteration 31700, loss=0.6801100969314575
Iteration 31800, loss=0.583548367023468
Iteration 31900, loss=0.7489386796951294
Iteration 32000, loss=0.09219031780958176
Iteration 32100, loss=0.76573646068573
Iteration 32200, loss=0.4935860335826874
Iteration 32300, loss=0.8740395307540894
Iteration 32400, loss=0.6883283257484436
Iteration 32500, loss=0.6676889657974243
Iteration 32600, loss=0.8106869459152222
Iteration 32700, loss=0.6606568694114685
Iteration 32800, loss=0.5758747458457947
Iteration 32900, loss=0.5792136192321777
Iteration 33000, loss=0.763375997543335
Iteration 33100, loss=0.5250045657157898
Iteration 33200, loss=0.6900461316108704
Iteration 33300, loss=0.7366000413894653
Iteration 33400, loss=0.6379352807998657
Iteration 33500, loss=0.44454124569892883
Iteration 33600, loss=0.2855105698108673
Iteration 33700, loss=0.600214421749115
Iteration 33800, loss=0.6949363350868225
Iteration 33900, loss=0.6050208806991577
Iteration 34000, loss=0.16037876904010773
Iteration 34100, loss=0.7225470542907715
Iteration 34200, loss=0.7881167531013489
Iteration 34300, loss=0.6364597082138062
Iteration 34400, loss=0.5456463098526001
Iteration 34500, loss=0.8066891431808472
Iteration 34600, loss=0.5415741801261902
Iteration 34700, loss=0.6676998734474182
Iteration 34800, loss=0.5441765189170837
Iteration 34900, loss=0.7692855596542358
Iteration 35000, loss=0.7772030830383301
Iteration 35100, loss=0.6191614270210266
Iteration 35200, loss=0.49799618124961853
Iteration 35300, loss=0.6181987524032593
Iteration 35400, loss=0.8476060628890991
Iteration 35500, loss=0.7543429136276245
Iteration 35600, loss=0.9009203314781189
Iteration 35700, loss=0.7429294586181641
Iteration 35800, loss=0.9766348600387573
Iteration 35900, loss=0.8072435855865479
Iteration 36000, loss=0.8843274116516113
Iteration 36100, loss=0.11734920740127563
Iteration 36200, loss=0.8288533687591553
Iteration 36300, loss=0.7017446160316467
Iteration 36400, loss=0.06541155278682709
Iteration 36500, loss=0.4660876989364624
Iteration 36600, loss=0.9553236961364746
Iteration 36700, loss=0.5357239842414856
Iteration 36800, loss=0.6182215213775635
Iteration 36900, loss=1.842615008354187
Iteration 37000, loss=0.09178364276885986
Iteration 37100, loss=0.721803605556488
Iteration 37200, loss=0.7350279092788696
Iteration 37300, loss=0.0931488499045372
Iteration 37400, loss=0.5653021931648254
Iteration 37500, loss=0.8205801844596863
Iteration 37600, loss=0.5638232827186584
Iteration 37700, loss=0.5190113186836243
Iteration 37800, loss=0.6403838992118835
Iteration 37900, loss=0.44222569465637207
Iteration 38000, loss=0.702154278755188
Iteration 38100, loss=0.7281277775764465
Iteration 38200, loss=0.7092457413673401
Iteration 38300, loss=0.760011613368988
Iteration 38400, loss=0.5797950029373169
Iteration 38500, loss=0.5933979749679565
Iteration 38600, loss=0.5895920395851135
Iteration 38700, loss=0.5058472752571106
Iteration 38800, loss=0.7169060707092285
Iteration 38900, loss=0.6389735341072083
Iteration 39000, loss=0.6571348905563354
Iteration 39100, loss=0.577987015247345
Iteration 39200, loss=0.7879365086555481
Iteration 39300, loss=0.7906525731086731
Iteration 39400, loss=0.5704439282417297
Iteration 39500, loss=0.5696709752082825
Iteration 39600, loss=0.7785589098930359
Iteration 39700, loss=0.5918348431587219
Iteration 39800, loss=0.6029778718948364
Iteration 39900, loss=0.5724998116493225
Iteration 40000, loss=0.5863305926322937
{'four': 0.64040434, 'artist': 0.6421651, 'zero': 0.6424458, 'roma': 0.6610524, 'businesses': 0.66658324, 'one': 0.66700083, 'lowest': 0.67198527, 'broadway': 0.6842358, 'circa': 0.71473545, 'eight': 1.0}
Iteration 40100, loss=1.1111831665039062
Iteration 40200, loss=0.7782856822013855
Iteration 40300, loss=0.7398085594177246
Iteration 40400, loss=0.6508678197860718
Iteration 40500, loss=0.5417831540107727
Iteration 40600, loss=0.6052550077438354
Iteration 40700, loss=0.6321330070495605
Iteration 40800, loss=0.9419667720794678
Iteration 40900, loss=0.8566628694534302
Iteration 41000, loss=1.928981900215149
Iteration 41100, loss=0.7081105709075928
Iteration 41200, loss=0.7142415046691895
Iteration 41300, loss=0.2140362560749054
Iteration 41400, loss=0.8842953443527222
Iteration 41500, loss=0.8864096999168396
Iteration 41600, loss=0.7497086524963379
Iteration 41700, loss=0.5134788751602173
Iteration 41800, loss=0.8508578538894653
Iteration 41900, loss=0.7962279319763184
Iteration 42000, loss=0.6662880778312683
Iteration 42100, loss=0.12336556613445282
Iteration 42200, loss=0.7292307615280151
Iteration 42300, loss=1.4709186553955078
Iteration 42400, loss=0.6080359220504761
Iteration 42500, loss=0.6146590709686279
Iteration 42600, loss=0.8835494518280029
Iteration 42700, loss=0.7468572854995728
Iteration 42800, loss=0.5841528177261353
Iteration 42900, loss=1.1627633571624756
Iteration 43000, loss=1.1970127820968628
Iteration 43100, loss=0.5420740246772766
Iteration 43200, loss=0.859105110168457
Iteration 43300, loss=0.46145686507225037
Iteration 43400, loss=0.45040395855903625
Iteration 43500, loss=3.374904155731201
Iteration 43600, loss=0.8598852157592773
Iteration 43700, loss=1.801207423210144
Iteration 43800, loss=0.5842844247817993
Iteration 43900, loss=0.0633009597659111
Iteration 44000, loss=0.6377368569374084
Iteration 44100, loss=0.5642593502998352
Iteration 44200, loss=0.8070724010467529
Iteration 44300, loss=0.8289682269096375
Iteration 44400, loss=0.7941741347312927
Iteration 44500, loss=0.5993998050689697
Iteration 44600, loss=0.5199480056762695
Iteration 44700, loss=0.5482943058013916
Iteration 44800, loss=0.6166962385177612
Iteration 44900, loss=0.7896581888198853
Iteration 45000, loss=0.7340494394302368
Iteration 45100, loss=0.8530558347702026
Iteration 45200, loss=0.41413554549217224
Iteration 45300, loss=0.6889697909355164
Iteration 45400, loss=0.31809377670288086
Iteration 45500, loss=0.5882036089897156
Iteration 45600, loss=0.4970215857028961
Iteration 45700, loss=1.1606848239898682
Iteration 45800, loss=0.008911583572626114
Iteration 45900, loss=0.6557469964027405
Iteration 46000, loss=0.532818078994751
Iteration 46100, loss=1.552537441253662
Iteration 46200, loss=0.5415384769439697
Iteration 46300, loss=0.8370165228843689
Iteration 46400, loss=0.04250238090753555
Iteration 46500, loss=0.06042075902223587
Iteration 46600, loss=0.2027956247329712
Iteration 46700, loss=0.5690730810165405
Iteration 46800, loss=0.6219965219497681
Iteration 46900, loss=1.3748648166656494
Iteration 47000, loss=0.5974274277687073
Iteration 47100, loss=0.580335795879364
Iteration 47200, loss=0.7046943306922913
Iteration 47300, loss=0.6265138983726501
Iteration 47400, loss=0.6478167772293091
Iteration 47500, loss=0.7147589921951294
Iteration 47600, loss=0.600958526134491
Iteration 47700, loss=0.749866247177124
Iteration 47800, loss=0.8635109663009644
Iteration 47900, loss=0.043598759919404984
Iteration 48000, loss=0.4886488914489746
Iteration 48100, loss=0.8085121512413025
Iteration 48200, loss=0.5256837010383606
Iteration 48300, loss=0.5180431604385376
Iteration 48400, loss=0.6712027788162231
Iteration 48500, loss=0.6206386089324951
Iteration 48600, loss=0.5024243593215942
Iteration 48700, loss=0.6359706521034241
Iteration 48800, loss=0.6190944314002991
Iteration 48900, loss=0.07995130121707916
Iteration 49000, loss=0.4132656455039978
Iteration 49100, loss=0.5370592474937439
Iteration 49200, loss=0.8293663859367371
Iteration 49300, loss=0.8428562879562378
Iteration 49400, loss=0.8523311018943787
Iteration 49500, loss=0.5884279012680054
Iteration 49600, loss=0.6413080096244812
Iteration 49700, loss=0.5922195315361023
Iteration 49800, loss=0.8335598707199097
Iteration 49900, loss=0.6198579668998718
Iteration 50000, loss=0.08981790393590927
{'complaint': 0.6326879, 'a': 0.64243186, 'pakistani': 0.64345545, 's': 0.64559996, 'activities': 0.650492, 'minutes': 0.6536351, 'changes': 0.66249794, 'ruling': 0.66920286, 'circa': 0.68369114, 'eight': 1.0000001}
Iteration 50100, loss=0.7274863719940186
Iteration 50200, loss=0.5171696543693542
Iteration 50300, loss=0.24060657620429993
Iteration 50400, loss=0.668544352054596
Iteration 50500, loss=0.5244656801223755
Iteration 50600, loss=0.7127672433853149
Iteration 50700, loss=0.8341500163078308
Iteration 50800, loss=1.9335263967514038
Iteration 50900, loss=0.5947942733764648
Iteration 51000, loss=0.6623453497886658
Iteration 51100, loss=0.9182802438735962
Iteration 51200, loss=0.673167884349823
Iteration 51300, loss=0.4940287172794342
Iteration 51400, loss=0.5235418081283569
Iteration 51500, loss=0.62943434715271
Iteration 51600, loss=0.7991135120391846
Iteration 51700, loss=0.5735713243484497
Iteration 51800, loss=0.566567599773407
Iteration 51900, loss=0.6095717549324036
Iteration 52000, loss=0.681463360786438
Iteration 52100, loss=0.664376974105835
Iteration 52200, loss=0.5021113157272339
Iteration 52300, loss=0.9938378930091858
Iteration 52400, loss=0.3612695038318634
Iteration 52500, loss=0.5073655247688293
Iteration 52600, loss=0.1736641675233841
Iteration 52700, loss=0.6520703434944153
Iteration 52800, loss=0.4045960307121277
Iteration 52900, loss=1.0178301334381104
Iteration 53000, loss=0.5510314106941223
Iteration 53100, loss=0.46323254704475403
Iteration 53200, loss=0.58137047290802
Iteration 53300, loss=0.4875744879245758
Iteration 53400, loss=0.6011679768562317
Iteration 53500, loss=0.014214945025742054
Iteration 53600, loss=0.02408473938703537
Iteration 53700, loss=0.31160643696784973
Iteration 53800, loss=0.41098910570144653
Iteration 53900, loss=1.0900003910064697
Iteration 54000, loss=0.4086571931838989
Iteration 54100, loss=1.4174703359603882
Iteration 54200, loss=1.2339612245559692
Iteration 54300, loss=0.8527585864067078
Iteration 54400, loss=0.499381422996521
Iteration 54500, loss=0.026811987161636353
Iteration 54600, loss=0.5059826374053955
Iteration 54700, loss=0.7565508484840393
Iteration 54800, loss=0.6124032139778137
Iteration 54900, loss=0.20428460836410522
Iteration 55000, loss=0.5603252649307251
Iteration 55100, loss=0.5796945691108704
Iteration 55200, loss=1.1094448566436768
Iteration 55300, loss=0.5179035067558289
Iteration 55400, loss=0.5934615135192871
Iteration 55500, loss=0.22704415023326874
Iteration 55600, loss=0.8701798915863037
Iteration 55700, loss=0.4877898395061493
Iteration 55800, loss=0.5797412991523743
Iteration 55900, loss=0.9030134081840515
Iteration 56000, loss=0.6646936535835266
Iteration 56100, loss=2.326749086380005
Iteration 56200, loss=0.885786771774292
Iteration 56300, loss=0.9453301429748535
Iteration 56400, loss=0.4799010455608368
Iteration 56500, loss=0.5166730284690857
Iteration 56600, loss=0.6268835663795471
Iteration 56700, loss=0.623559832572937
Iteration 56800, loss=1.22542405128479
Iteration 56900, loss=0.6136813759803772
Iteration 57000, loss=0.7365180850028992
Iteration 57100, loss=0.9181462526321411
Iteration 57200, loss=0.8062291741371155
Iteration 57300, loss=0.012750405818223953
Iteration 57400, loss=0.9373593330383301
Iteration 57500, loss=0.8126909732818604
Iteration 57600, loss=0.8240238428115845
Iteration 57700, loss=0.5579192042350769
Iteration 57800, loss=0.6298006772994995
Iteration 57900, loss=0.5906036496162415
Iteration 58000, loss=0.6987435817718506
Iteration 58100, loss=0.6320924758911133
Iteration 58200, loss=0.05102759599685669
Iteration 58300, loss=0.5688068270683289
Iteration 58400, loss=0.7845562696456909
Iteration 58500, loss=0.7941615581512451
Iteration 58600, loss=0.9767892360687256
Iteration 58700, loss=1.0647345781326294
Iteration 58800, loss=0.8948532938957214
Iteration 58900, loss=0.6637862324714661
Iteration 59000, loss=0.45682087540626526
Iteration 59100, loss=0.9822627305984497
Iteration 59200, loss=0.4707668125629425
Iteration 59300, loss=0.6232413053512573
Iteration 59400, loss=0.6010820865631104
Iteration 59500, loss=0.7288080453872681
Iteration 59600, loss=0.5996788144111633
Iteration 59700, loss=0.924546480178833
Iteration 59800, loss=0.541768491268158
Iteration 59900, loss=1.0560691356658936
Iteration 60000, loss=1.1064393520355225
{'winter': 0.613382, 'ruling': 0.61651194, 's': 0.62001467, 'activities': 0.6211503, 'complaint': 0.6346245, 'year': 0.6349876, 'changes': 0.6588261, 'circa': 0.68828976, 'josef': 0.71935505, 'eight': 1.0}
Iteration 60100, loss=0.5336146354675293
Iteration 60200, loss=0.5168594717979431
Iteration 60300, loss=0.459342896938324
Iteration 60400, loss=0.7240945100784302
Iteration 60500, loss=0.6422545313835144
Iteration 60600, loss=0.6068088412284851
Iteration 60700, loss=0.6414869427680969
Iteration 60800, loss=0.38706639409065247
Iteration 60900, loss=0.6979997158050537
Iteration 61000, loss=0.5589514970779419
Iteration 61100, loss=0.5136274695396423
Iteration 61200, loss=0.4467194080352783
Iteration 61300, loss=0.543637752532959
Iteration 61400, loss=0.8816622495651245
Iteration 61500, loss=0.08095504343509674
Iteration 61600, loss=0.7018203735351562
Iteration 61700, loss=0.2938902676105499
Iteration 61800, loss=0.9232114553451538
Iteration 61900, loss=0.5134357213973999
Iteration 62000, loss=0.06128925085067749
Iteration 62100, loss=0.5487748980522156
Iteration 62200, loss=0.3883584439754486
Iteration 62300, loss=0.9611643552780151
Iteration 62400, loss=0.80594801902771
Iteration 62500, loss=0.5005381107330322
Iteration 62600, loss=0.7366764545440674
Iteration 62700, loss=0.661588728427887
Iteration 62800, loss=0.7601186633110046
Iteration 62900, loss=0.4786251485347748
Iteration 63000, loss=0.8336640000343323
Iteration 63100, loss=0.5766305327415466
Iteration 63200, loss=0.14485105872154236
Iteration 63300, loss=0.489461213350296
Iteration 63400, loss=1.4515973329544067
Iteration 63500, loss=0.8896097540855408
Iteration 63600, loss=0.42703884840011597
Iteration 63700, loss=0.5539838075637817
Iteration 63800, loss=0.6252646446228027
Iteration 63900, loss=0.9268192648887634
Iteration 64000, loss=0.27602648735046387
Iteration 64100, loss=1.6940876245498657
Iteration 64200, loss=0.7769400477409363
Iteration 64300, loss=0.8292809724807739
Iteration 64400, loss=0.2018512785434723
Iteration 64500, loss=0.0019854966085404158
Iteration 64600, loss=0.5742320418357849
Iteration 64700, loss=0.7258973121643066
Iteration 64800, loss=0.7852329611778259
Iteration 64900, loss=0.6340704560279846
Iteration 65000, loss=0.8975620865821838
Iteration 65100, loss=0.6565470695495605
Iteration 65200, loss=0.5539366602897644
Iteration 65300, loss=0.5339816212654114
Iteration 65400, loss=0.5363996028900146
Iteration 65500, loss=0.0317998006939888
Iteration 65600, loss=0.49381956458091736
Iteration 65700, loss=1.0214427709579468
Iteration 65800, loss=0.7989234328269958
Iteration 65900, loss=0.7270551919937134
Iteration 66000, loss=0.6373903751373291
Iteration 66100, loss=0.5069470405578613
Iteration 66200, loss=0.5384127497673035
Iteration 66300, loss=0.8248637914657593
Iteration 66400, loss=0.528193473815918
Iteration 66500, loss=0.9125766158103943
Iteration 66600, loss=1.0376572608947754
Iteration 66700, loss=0.4370548725128174
Iteration 66800, loss=0.5041611194610596
Iteration 66900, loss=0.5239432454109192
Iteration 67000, loss=0.759737491607666
Iteration 67100, loss=0.5535294413566589
Iteration 67200, loss=0.5552607774734497
Iteration 67300, loss=0.5223568081855774
Iteration 67400, loss=0.5836451649665833
Iteration 67500, loss=0.7807828783988953
Iteration 67600, loss=0.600009560585022
Iteration 67700, loss=0.5891494154930115
Iteration 67800, loss=0.524755597114563
Iteration 67900, loss=0.8470803499221802
Iteration 68000, loss=0.6511883735656738
Iteration 68100, loss=0.5036069750785828
Iteration 68200, loss=0.558809220790863
Iteration 68300, loss=0.8270988464355469
Iteration 68400, loss=0.4148608446121216
Iteration 68500, loss=0.8479623794555664
Iteration 68600, loss=0.5982102751731873
Iteration 68700, loss=0.5384953022003174
Iteration 68800, loss=0.6112141609191895
Iteration 68900, loss=0.8178926110267639
Iteration 69000, loss=0.24012914299964905
Iteration 69100, loss=0.4876111149787903
Iteration 69200, loss=0.9169602394104004
Iteration 69300, loss=0.41031569242477417
Iteration 69400, loss=0.5038470029830933
Iteration 69500, loss=0.7733353972434998
Iteration 69600, loss=0.6861976385116577
Iteration 69700, loss=0.6239916086196899
Iteration 69800, loss=0.49835681915283203
Iteration 69900, loss=0.5680701732635498
Iteration 70000, loss=0.5756387114524841
{'a': 0.68797636, 'constantinople': 0.6883484, 'complaint': 0.69162124, 'independent': 0.6974782, 'winter': 0.6993082, 'substrate': 0.701931, 'year': 0.72121704, 'ruling': 0.7238485, 'circa': 0.7823533, 'eight': 1.0}
Iteration 70100, loss=0.609109103679657
Iteration 70200, loss=0.5442730784416199
Iteration 70300, loss=0.5129256844520569
Iteration 70400, loss=0.5626816749572754
Iteration 70500, loss=0.5140963792800903
Iteration 70600, loss=1.3358839750289917
Iteration 70700, loss=0.7872358560562134
Iteration 70800, loss=0.48448577523231506
Iteration 70900, loss=0.5288337469100952
Iteration 71000, loss=0.5375503301620483
Iteration 71100, loss=0.5431241393089294
Iteration 71200, loss=0.9367839097976685
Iteration 71300, loss=0.5575667023658752
Iteration 71400, loss=0.771364152431488
Iteration 71500, loss=0.29069554805755615
Iteration 71600, loss=0.1535671353340149
Iteration 71700, loss=0.5157268643379211
Iteration 71800, loss=0.47943100333213806
Iteration 71900, loss=0.5281399488449097
Iteration 72000, loss=0.5232877731323242
Iteration 72100, loss=0.948188304901123
Iteration 72200, loss=0.88893061876297
Iteration 72300, loss=1.7431529760360718
Iteration 72400, loss=0.0417647510766983
Iteration 72500, loss=0.46850135922431946
Iteration 72600, loss=0.7640774250030518
Iteration 72700, loss=0.49999648332595825
Iteration 72800, loss=0.4844762682914734
Iteration 72900, loss=0.7659818530082703
Iteration 73000, loss=0.5823873281478882
Iteration 73100, loss=0.5934993624687195
Iteration 73200, loss=0.7515825629234314
Iteration 73300, loss=0.518596887588501
Iteration 73400, loss=0.5490458607673645
Iteration 73500, loss=0.7033302783966064
Iteration 73600, loss=0.44108182191848755
Iteration 73700, loss=0.44098037481307983
Iteration 73800, loss=0.5048053860664368
Iteration 73900, loss=0.4968477487564087
Iteration 74000, loss=0.5173865556716919
Iteration 74100, loss=0.6319103240966797
Iteration 74200, loss=0.48684224486351013
Iteration 74300, loss=0.2920983135700226
Iteration 74400, loss=0.3417889475822449
Iteration 74500, loss=0.5578608512878418
Iteration 74600, loss=0.9932161569595337
Iteration 74700, loss=0.38549163937568665
Iteration 74800, loss=2.3020095825195312
Iteration 74900, loss=0.02619323320686817
Iteration 75000, loss=0.4793257713317871
Iteration 75100, loss=0.5368021726608276
Iteration 75200, loss=0.3483068346977234
Iteration 75300, loss=0.8342954516410828
Iteration 75400, loss=0.7915108799934387
Iteration 75500, loss=0.5079895257949829
Iteration 75600, loss=0.21821488440036774
Iteration 75700, loss=0.5329284071922302
Iteration 75800, loss=0.508107602596283
Iteration 75900, loss=0.8844196796417236
Iteration 76000, loss=0.5336833596229553
Iteration 76100, loss=0.5407450795173645
Iteration 76200, loss=0.5410535931587219
Iteration 76300, loss=0.09106919914484024
Iteration 76400, loss=0.8781917095184326
Iteration 76500, loss=0.03399502485990524
Iteration 76600, loss=0.05314475670456886
Iteration 76700, loss=0.7810568809509277
Iteration 76800, loss=0.12040899693965912
Iteration 76900, loss=0.5177366137504578
Iteration 77000, loss=0.06695200502872467
Iteration 77100, loss=0.5610498785972595
Iteration 77200, loss=0.5754498243331909
Iteration 77300, loss=0.7568949460983276
Iteration 77400, loss=0.8765966296195984
Iteration 77500, loss=0.56401127576828
Iteration 77600, loss=1.27778160572052
Iteration 77700, loss=0.7015769481658936
Iteration 77800, loss=0.5495828986167908
Iteration 77900, loss=0.4303189814090729
Iteration 78000, loss=0.5615137219429016
Iteration 78100, loss=0.5061588287353516
Iteration 78200, loss=0.44203659892082214
Iteration 78300, loss=0.7528191804885864
Iteration 78400, loss=0.7749008536338806
Iteration 78500, loss=0.28688859939575195
Iteration 78600, loss=0.4160480201244354
Iteration 78700, loss=0.44356483221054077
Iteration 78800, loss=0.52622389793396
Iteration 78900, loss=0.5143736600875854
Iteration 79000, loss=0.9977784156799316
Iteration 79100, loss=0.31064775586128235
Iteration 79200, loss=0.9122723340988159
Iteration 79300, loss=0.21644559502601624
Iteration 79400, loss=0.33022016286849976
Iteration 79500, loss=0.5324485301971436
Iteration 79600, loss=0.2865005135536194
Iteration 79700, loss=0.7877545356750488
Iteration 79800, loss=0.8420085906982422
Iteration 79900, loss=0.4313217103481293
Iteration 80000, loss=0.5370376110076904
{'josef': 0.6720361, 'one': 0.67760736, 'zero': 0.6845837, 'complaint': 0.6868628, 'a': 0.68709904, 'independent': 0.6871334, 'year': 0.6977542, 'ruling': 0.7039401, 'circa': 0.75714844, 'eight': 1.0}
Iteration 80100, loss=0.5094231367111206
Iteration 80200, loss=0.5147631764411926
Iteration 80300, loss=0.9061383008956909
Iteration 80400, loss=0.6904376149177551
Iteration 80500, loss=0.5996557474136353
Iteration 80600, loss=0.875491201877594
Iteration 80700, loss=0.7940844893455505
Iteration 80800, loss=0.8205873370170593
Iteration 80900, loss=0.12122368812561035
Iteration 81000, loss=0.5841576457023621
Iteration 81100, loss=0.3756725788116455
Iteration 81200, loss=0.6004646420478821
Iteration 81300, loss=0.008388010784983635
Iteration 81400, loss=0.6725033521652222
Iteration 81500, loss=0.5379707217216492
Iteration 81600, loss=0.5143367648124695
Iteration 81700, loss=1.0045968294143677
Iteration 81800, loss=0.5082067847251892
Iteration 81900, loss=0.07102300971746445
Iteration 82000, loss=0.5778820514678955
Iteration 82100, loss=0.824702799320221
Iteration 82200, loss=1.7434343099594116
Iteration 82300, loss=0.5341757535934448
Iteration 82400, loss=0.5384933352470398
Iteration 82500, loss=0.8919118642807007
Iteration 82600, loss=0.4930124580860138
Iteration 82700, loss=0.09183947741985321
Iteration 82800, loss=1.3501949310302734
Iteration 82900, loss=0.14774681627750397
Iteration 83000, loss=0.5397061109542847
Iteration 83100, loss=0.3288458585739136
Iteration 83200, loss=0.37904074788093567
Iteration 83300, loss=0.8085376620292664
Iteration 83400, loss=0.2044743448495865
Iteration 83500, loss=0.4479261636734009
Iteration 83600, loss=0.42505863308906555
Iteration 83700, loss=0.29184994101524353
Iteration 83800, loss=0.5029358267784119
Iteration 83900, loss=0.5471946597099304
Iteration 84000, loss=0.7027076482772827
Iteration 84100, loss=0.5289492011070251
Iteration 84200, loss=0.12955409288406372
Iteration 84300, loss=0.2760414779186249
Iteration 84400, loss=0.661202609539032
Iteration 84500, loss=0.005552623420953751
Iteration 84600, loss=0.5326271653175354
Iteration 84700, loss=0.5579466819763184
Iteration 84800, loss=0.5356320142745972
Iteration 84900, loss=0.8190562129020691
Iteration 85000, loss=1.1170943975448608
Iteration 85100, loss=0.5219764113426208
Iteration 85200, loss=0.5687191486358643
Iteration 85300, loss=0.7111185789108276
Iteration 85400, loss=0.65752774477005
Iteration 85500, loss=0.20564842224121094
Iteration 85600, loss=0.6100999712944031
Iteration 85700, loss=0.5658608078956604
Iteration 85800, loss=0.5206694602966309
Iteration 85900, loss=0.482307106256485
Iteration 86000, loss=1.0982252359390259
Iteration 86100, loss=0.46748974919319153
Iteration 86200, loss=0.4993259310722351
Iteration 86300, loss=0.6021946668624878
Iteration 86400, loss=1.0451693534851074
Iteration 86500, loss=0.49890804290771484
Iteration 86600, loss=0.8304094076156616
Iteration 86700, loss=0.6110760569572449
Iteration 86800, loss=0.4851458668708801
Iteration 86900, loss=0.6311699151992798
Iteration 87000, loss=0.4576089680194855
Iteration 87100, loss=0.8362226486206055
Iteration 87200, loss=0.8142156600952148
Iteration 87300, loss=0.49172163009643555
Iteration 87400, loss=0.4738686978816986
Iteration 87500, loss=0.4642346203327179
Iteration 87600, loss=0.6465679407119751
Iteration 87700, loss=1.838987112045288
Iteration 87800, loss=0.5624118447303772
Iteration 87900, loss=0.5248767137527466
Iteration 88000, loss=0.9808363914489746
Iteration 88100, loss=0.8609716892242432
Iteration 88200, loss=0.503166913986206
Iteration 88300, loss=0.4104703664779663
Iteration 88400, loss=1.263914942741394
Iteration 88500, loss=0.9155914187431335
Iteration 88600, loss=0.6726012229919434
Iteration 88700, loss=0.5683419108390808
Iteration 88800, loss=0.5036056637763977
Iteration 88900, loss=0.7445706725120544
Iteration 89000, loss=0.5452799797058105
Iteration 89100, loss=0.5936165452003479
Iteration 89200, loss=0.5996062755584717
Iteration 89300, loss=0.26367008686065674
Iteration 89400, loss=0.5682699084281921
Iteration 89500, loss=0.5514301061630249
Iteration 89600, loss=0.6246283054351807
Iteration 89700, loss=0.6987653374671936
Iteration 89800, loss=0.5395777821540833
Iteration 89900, loss=0.44703230261802673
Iteration 90000, loss=0.6039418578147888
{'official': 0.7197662, 'microsoft': 0.7212097, 'a': 0.7214903, 'zero': 0.7219879, 'independent': 0.7221794, 'josef': 0.7251495, 'ruling': 0.74119383, 'one': 0.7426017, 'circa': 0.76785535, 'eight': 1.0000001}
Iteration 90100, loss=0.812387228012085
Iteration 90200, loss=1.725330114364624
Iteration 90300, loss=0.5428019165992737
Iteration 90400, loss=0.5810282826423645
Iteration 90500, loss=0.442012757062912
Iteration 90600, loss=0.5519660711288452
Iteration 90700, loss=0.8225787281990051
Iteration 90800, loss=0.3778024911880493
Iteration 90900, loss=0.8875407576560974
Iteration 91000, loss=0.4726387560367584
Iteration 91100, loss=0.5084191560745239
Iteration 91200, loss=0.7998266816139221
Iteration 91300, loss=0.8328965306282043
Iteration 91400, loss=1.035569429397583
Iteration 91500, loss=1.0187042951583862
Iteration 91600, loss=0.43050217628479004
Iteration 91700, loss=0.5762075781822205
Iteration 91800, loss=0.8691670298576355
Iteration 91900, loss=0.2271922081708908
Iteration 92000, loss=0.5567209720611572
Iteration 92100, loss=0.8965471982955933
Iteration 92200, loss=0.3449813425540924
Iteration 92300, loss=0.21470922231674194
Iteration 92400, loss=0.6130117774009705
Iteration 92500, loss=0.023029908537864685
Iteration 92600, loss=0.5652016997337341
Iteration 92700, loss=0.7340635061264038
Iteration 92800, loss=0.15813526511192322
Iteration 92900, loss=0.6256992220878601
Iteration 93000, loss=0.5479690432548523
Iteration 93100, loss=0.948785126209259
Iteration 93200, loss=0.7990413904190063
Iteration 93300, loss=0.5280980467796326
Iteration 93400, loss=0.7095964550971985
Iteration 93500, loss=0.5945111513137817
Iteration 93600, loss=1.4280341863632202
Iteration 93700, loss=0.945048451423645
Iteration 93800, loss=0.6606307029724121
Iteration 93900, loss=0.9013911485671997
Iteration 94000, loss=0.5692233443260193
Iteration 94100, loss=0.5116997957229614
Iteration 94200, loss=0.1642325222492218
Iteration 94300, loss=0.7144099473953247
Iteration 94400, loss=0.33046379685401917
Iteration 94500, loss=0.8947091102600098
Iteration 94600, loss=0.542396068572998
Iteration 94700, loss=0.957197904586792
Iteration 94800, loss=0.4965842068195343
Iteration 94900, loss=0.8282618522644043
Iteration 95000, loss=0.5250810384750366
Iteration 95100, loss=0.628264307975769
Iteration 95200, loss=0.5672674775123596
Iteration 95300, loss=0.8950521945953369
Iteration 95400, loss=0.8661067485809326
Iteration 95500, loss=0.2516454756259918
Iteration 95600, loss=0.45835939049720764
Iteration 95700, loss=0.5573045015335083
Iteration 95800, loss=0.5273388624191284
Iteration 95900, loss=0.5560293197631836
Iteration 96000, loss=0.7026442885398865
Iteration 96100, loss=0.547305703163147
Iteration 96200, loss=0.4384644031524658
Iteration 96300, loss=0.3868355453014374
Iteration 96400, loss=0.5984250903129578
Iteration 96500, loss=0.47020772099494934
Iteration 96600, loss=0.5602453351020813
Iteration 96700, loss=0.4003208875656128
Iteration 96800, loss=0.5656918883323669
Iteration 96900, loss=0.5740330219268799
Iteration 97000, loss=1.0243306159973145
Iteration 97100, loss=1.0411518812179565
Iteration 97200, loss=0.21211160719394684
Iteration 97300, loss=0.017558611929416656
Iteration 97400, loss=0.5910735726356506
Iteration 97500, loss=1.028117299079895
Iteration 97600, loss=0.6698398590087891
Iteration 97700, loss=0.8275654911994934
Iteration 97800, loss=0.7049902081489563
Iteration 97900, loss=0.5100694298744202
Iteration 98000, loss=0.5080203413963318
Iteration 98100, loss=0.9990175366401672
Iteration 98200, loss=0.5857625603675842
Iteration 98300, loss=0.7592531442642212
Iteration 98400, loss=2.734394365688786e-05
Iteration 98500, loss=0.6206406950950623
Iteration 98600, loss=0.9634897708892822
Iteration 98700, loss=0.35843899846076965
Iteration 98800, loss=0.9878016710281372
Iteration 98900, loss=0.5533718466758728
Iteration 99000, loss=0.7625324726104736
Iteration 99100, loss=0.5452669858932495
Iteration 99200, loss=0.9779422879219055
Iteration 99300, loss=0.5485653281211853
Iteration 99400, loss=0.04054476320743561
Iteration 99500, loss=0.07526133954524994
Iteration 99600, loss=0.5779476761817932
Iteration 99700, loss=0.6326836347579956
Iteration 99800, loss=1.0975310802459717
Iteration 99900, loss=0.4954354166984558
Iteration 100000, loss=0.6655673980712891
{'complaint': 0.75129926, 'germany': 0.75335956, 'microsoft': 0.75564504, 'between': 0.75635695, 'year': 0.756862, 'deceased': 0.76609606, 'a': 0.77218395, 'circa': 0.7761588, 'official': 0.78699034, 'eight': 0.9999999}
Iteration 100100, loss=0.49070093035697937
Iteration 100200, loss=0.6948261260986328
Iteration 100300, loss=0.5352206826210022
Iteration 100400, loss=0.709590494632721
Iteration 100500, loss=0.005094421096146107
Iteration 100600, loss=0.9764089584350586
Iteration 100700, loss=0.6000091433525085
Iteration 100800, loss=0.32602107524871826
Iteration 100900, loss=1.055631399154663
Iteration 101000, loss=0.0007080197101458907
Iteration 101100, loss=0.6204938292503357
Iteration 101200, loss=0.856355607509613
Iteration 101300, loss=0.5404622554779053
Iteration 101400, loss=0.7591305375099182
Iteration 101500, loss=0.03575408458709717
Iteration 101600, loss=0.4231058657169342
Iteration 101700, loss=0.6417630314826965
Iteration 101800, loss=0.576610267162323
Iteration 101900, loss=0.7361311912536621
Iteration 102000, loss=3.0560579034499824e-05
Iteration 102100, loss=0.8342047929763794
Iteration 102200, loss=0.5247249603271484
Iteration 102300, loss=0.10903705656528473
Iteration 102400, loss=1.0358850955963135
Iteration 102500, loss=1.259871244430542
Iteration 102600, loss=0.8775058388710022
Iteration 102700, loss=0.885908842086792
Iteration 102800, loss=0.5066009759902954
Iteration 102900, loss=0.5877505540847778
Iteration 103000, loss=0.5233455896377563
Iteration 103100, loss=0.2870750427246094
Iteration 103200, loss=0.6838875412940979
Iteration 103300, loss=0.0013848096132278442
Iteration 103400, loss=0.626591682434082
Iteration 103500, loss=0.5069804191589355
Iteration 103600, loss=0.5756422281265259
Iteration 103700, loss=1.0866774320602417
Iteration 103800, loss=0.5065953731536865
Iteration 103900, loss=0.4994533956050873
Iteration 104000, loss=0.8293784856796265
Iteration 104100, loss=0.6169103980064392
Iteration 104200, loss=0.8674948215484619
Iteration 104300, loss=0.5401736497879028
Iteration 104400, loss=0.6586347818374634
Iteration 104500, loss=0.35767191648483276
Iteration 104600, loss=0.9793903827667236
Iteration 104700, loss=0.5098766088485718
Iteration 104800, loss=0.8526616096496582
Iteration 104900, loss=0.8202546834945679
Iteration 105000, loss=0.8595986366271973
Iteration 105100, loss=0.1327393800020218
Iteration 105200, loss=0.8189557194709778
Iteration 105300, loss=1.5106364488601685
Iteration 105400, loss=0.4935629367828369
Iteration 105500, loss=0.40624111890792847
Iteration 105600, loss=0.7260541915893555
Iteration 105700, loss=0.26509949564933777
Iteration 105800, loss=0.4017452597618103
Iteration 105900, loss=0.473011314868927
Iteration 106000, loss=0.4927329123020172
Iteration 106100, loss=0.5252816677093506
Iteration 106200, loss=0.7238494157791138
Iteration 106300, loss=0.39507925510406494
Iteration 106400, loss=0.914023756980896
Iteration 106500, loss=0.9426740407943726
Iteration 106600, loss=0.3722280263900757
Iteration 106700, loss=0.46688467264175415
Iteration 106800, loss=0.15014798939228058
Iteration 106900, loss=0.26044851541519165
Iteration 107000, loss=0.5111708045005798
Iteration 107100, loss=0.3407919704914093
Iteration 107200, loss=0.3627758026123047
Iteration 107300, loss=0.6509160399436951
Iteration 107400, loss=0.7950555682182312
Iteration 107500, loss=0.5079025030136108
Iteration 107600, loss=0.5068086981773376
Iteration 107700, loss=0.9542012214660645
Iteration 107800, loss=0.6705507040023804
Iteration 107900, loss=1.5998185873031616
Iteration 108000, loss=0.5362312197685242
Iteration 108100, loss=0.5749253034591675
Iteration 108200, loss=0.6575019359588623
Iteration 108300, loss=0.4988561272621155
Iteration 108400, loss=0.9025832414627075
Iteration 108500, loss=0.5521710515022278
Iteration 108600, loss=0.4523952603340149
Iteration 108700, loss=0.5273830890655518
Iteration 108800, loss=0.5705533027648926
Iteration 108900, loss=0.5049222111701965
Iteration 109000, loss=0.5757685303688049
Iteration 109100, loss=0.7082011699676514
Iteration 109200, loss=0.8436422348022461
Iteration 109300, loss=0.6994345188140869
Iteration 109400, loss=0.34317734837532043
Iteration 109500, loss=0.7091531753540039
Iteration 109600, loss=0.2543535828590393
Iteration 109700, loss=0.931204617023468
Iteration 109800, loss=0.2732599079608917
Iteration 109900, loss=1.097428321838379
Iteration 110000, loss=0.5891087651252747
{'one': 0.746946, 'publishers': 0.7540394, 'rd': 0.75506663, 'year': 0.75515884, 'suffered': 0.762189, 'a': 0.76514083, 'official': 0.7682051, 'j': 0.7730529, 'circa': 0.7864423, 'eight': 0.9999999}
Iteration 110100, loss=0.61859530210495
Iteration 110200, loss=0.7590248584747314
Iteration 110300, loss=0.5746932625770569
Iteration 110400, loss=0.5309121608734131
Iteration 110500, loss=0.4900447130203247
Iteration 110600, loss=1.388045072555542
Iteration 110700, loss=0.4486406445503235
Iteration 110800, loss=1.1736571788787842
Iteration 110900, loss=0.6195046901702881
Iteration 111000, loss=0.4914092421531677
Iteration 111100, loss=0.8410570621490479
Iteration 111200, loss=0.4509750306606293
Iteration 111300, loss=0.029528219252824783
Iteration 111400, loss=0.9637376070022583
Iteration 111500, loss=0.3807862102985382
Iteration 111600, loss=0.7665280699729919
Iteration 111700, loss=0.5267180800437927
Iteration 111800, loss=0.5073445439338684
Iteration 111900, loss=0.6457082033157349
Iteration 112000, loss=0.6845787167549133
Iteration 112100, loss=1.0156341791152954
Iteration 112200, loss=0.5476197004318237
Iteration 112300, loss=0.5364259481430054
Iteration 112400, loss=0.5799257159233093
Iteration 112500, loss=0.5452353358268738
Iteration 112600, loss=0.3085266947746277
Iteration 112700, loss=0.7235352993011475
Iteration 112800, loss=1.4192179441452026
Iteration 112900, loss=0.25843650102615356
Iteration 113000, loss=0.11461549997329712
Iteration 113100, loss=0.5310141444206238
Iteration 113200, loss=0.7197278738021851
Iteration 113300, loss=0.9430444240570068
Iteration 113400, loss=1.5318683385849
Iteration 113500, loss=0.5162171125411987
Iteration 113600, loss=0.5745998620986938
Iteration 113700, loss=0.8559295535087585
Iteration 113800, loss=0.6483538150787354
Iteration 113900, loss=0.605256974697113
Iteration 114000, loss=0.563402533531189
Iteration 114100, loss=0.21998843550682068
Iteration 114200, loss=0.6107956171035767
Iteration 114300, loss=0.591917097568512
Iteration 114400, loss=0.7752224802970886
Iteration 114500, loss=0.07107763737440109
Iteration 114600, loss=0.5131293535232544
Iteration 114700, loss=0.6869131922721863
Iteration 114800, loss=0.0014153321972116828
Iteration 114900, loss=0.11999237537384033
Iteration 115000, loss=0.3900432884693146
Iteration 115100, loss=0.6196584105491638
Iteration 115200, loss=1.139739751815796
Iteration 115300, loss=0.22850315272808075
Iteration 115400, loss=0.9180942177772522
Iteration 115500, loss=0.5763362050056458
Iteration 115600, loss=0.638946533203125
Iteration 115700, loss=0.44413796067237854
Iteration 115800, loss=0.5876960754394531
Iteration 115900, loss=0.778018593788147
Iteration 116000, loss=0.5194023847579956
Iteration 116100, loss=0.7742483615875244
Iteration 116200, loss=0.5891591310501099
Iteration 116300, loss=0.5418867468833923
Iteration 116400, loss=0.6877927184104919
Iteration 116500, loss=0.40630093216896057
Iteration 116600, loss=0.20136845111846924
Iteration 116700, loss=0.036878686398267746
Iteration 116800, loss=0.5320924520492554
Iteration 116900, loss=0.04001658037304878
Iteration 117000, loss=0.45277321338653564
Iteration 117100, loss=0.9064128398895264
Iteration 117200, loss=0.511054277420044
Iteration 117300, loss=0.8574905395507812
Iteration 117400, loss=0.2997218370437622
Iteration 117500, loss=0.317695677280426
Iteration 117600, loss=0.219743013381958
Iteration 117700, loss=0.8619928956031799
Iteration 117800, loss=0.0002883545821532607
Iteration 117900, loss=0.5651466846466064
Iteration 118000, loss=0.8177517652511597
Iteration 118100, loss=0.4624587297439575
Iteration 118200, loss=0.9192109107971191
Iteration 118300, loss=0.759771466255188
Iteration 118400, loss=0.48274359107017517
Iteration 118500, loss=0.648550271987915
Iteration 118600, loss=0.50204998254776
Iteration 118700, loss=0.5034788846969604
Iteration 118800, loss=1.3540705442428589
Iteration 118900, loss=0.9431413412094116
Iteration 119000, loss=0.47271183133125305
Iteration 119100, loss=0.16438306868076324
Iteration 119200, loss=0.502778172492981
Iteration 119300, loss=0.20509223639965057
Iteration 119400, loss=0.3387523591518402
Iteration 119500, loss=0.5052263736724854
Iteration 119600, loss=0.8953564167022705
Iteration 119700, loss=0.730318546295166
Iteration 119800, loss=0.6940915584564209
Iteration 119900, loss=0.7792720198631287
Iteration 120000, loss=0.0008154533570632339
{'j': 0.7829789, 'publishers': 0.7839432, 'x': 0.7847747, 'suffered': 0.78566635, 'the': 0.7869915, 'official': 0.7888461, 'one': 0.7896934, 'microsoft': 0.7907186, 'circa': 0.8066585, 'eight': 1.0}
Iteration 120100, loss=0.7350471019744873
Iteration 120200, loss=0.2732342779636383
Iteration 120300, loss=0.799778401851654
Iteration 120400, loss=0.5489298701286316
Iteration 120500, loss=0.5116190910339355
Iteration 120600, loss=0.56658935546875
Iteration 120700, loss=0.6982472538948059
Iteration 120800, loss=0.5439345836639404
Iteration 120900, loss=0.5689211487770081
Iteration 121000, loss=0.04442987218499184
Iteration 121100, loss=0.5183015465736389
Iteration 121200, loss=0.4870714843273163
Iteration 121300, loss=0.5953987240791321
Iteration 121400, loss=0.55128014087677
Iteration 121500, loss=0.16668878495693207
Iteration 121600, loss=0.7197226285934448
Iteration 121700, loss=0.7554715871810913
Iteration 121800, loss=0.6686607599258423
Iteration 121900, loss=0.802222728729248
Iteration 122000, loss=0.5461643934249878
Iteration 122100, loss=0.817767322063446
Iteration 122200, loss=0.9175657033920288
Iteration 122300, loss=0.37802037596702576
Iteration 122400, loss=0.5750192403793335
Iteration 122500, loss=0.5248906016349792
Iteration 122600, loss=0.08714359253644943
Iteration 122700, loss=0.9455332159996033
Iteration 122800, loss=0.650750458240509
Iteration 122900, loss=0.6586263179779053
Iteration 123000, loss=1.2108180522918701
Iteration 123100, loss=0.624602735042572
Iteration 123200, loss=0.2563929557800293
Iteration 123300, loss=0.5726891756057739
Iteration 123400, loss=0.5423714518547058
Iteration 123500, loss=0.0009891678346320987
Iteration 123600, loss=0.5171074867248535
Iteration 123700, loss=0.88155198097229
Iteration 123800, loss=0.5404881238937378
Iteration 123900, loss=0.5188411474227905
Iteration 124000, loss=0.44797781109809875
Iteration 124100, loss=0.4930431842803955
Iteration 124200, loss=0.6617186665534973
Iteration 124300, loss=0.9341992735862732
Iteration 124400, loss=0.5419635772705078
Iteration 124500, loss=0.33972084522247314
Iteration 124600, loss=0.6125103831291199
Iteration 124700, loss=0.5410940647125244
Iteration 124800, loss=1.2412843704223633
Iteration 124900, loss=1.2392382621765137
Iteration 125000, loss=0.47800949215888977
Iteration 125100, loss=0.488629549741745
Iteration 125200, loss=0.48849454522132874
Iteration 125300, loss=0.46701112389564514
Iteration 125400, loss=0.31932541728019714
Iteration 125500, loss=0.5049991011619568
Iteration 125600, loss=1.0757691860198975
Iteration 125700, loss=0.18835902214050293
Iteration 125800, loss=0.9138609170913696
Iteration 125900, loss=0.604966402053833
Iteration 126000, loss=0.26770496368408203
Iteration 126100, loss=0.5677531957626343
Iteration 126200, loss=0.46938878297805786
Iteration 126300, loss=0.44590696692466736
Iteration 126400, loss=0.10017643123865128
Iteration 126500, loss=0.5116356611251831
Iteration 126600, loss=0.5668954849243164
Iteration 126700, loss=2.710280179977417
Iteration 126800, loss=0.7978833317756653
Iteration 126900, loss=0.10044655948877335
Iteration 127000, loss=0.4868682026863098
Iteration 127100, loss=0.7534369230270386
Iteration 127200, loss=0.992820143699646
Iteration 127300, loss=0.7847765684127808
Iteration 127400, loss=0.11839456111192703
Iteration 127500, loss=0.5379074811935425
Iteration 127600, loss=1.1378560066223145
Iteration 127700, loss=0.3564189076423645
Iteration 127800, loss=0.6015745997428894
Iteration 127900, loss=0.07591135054826736
Iteration 128000, loss=0.6735373735427856
Iteration 128100, loss=0.0013923647347837687
Iteration 128200, loss=0.8396986126899719
Iteration 128300, loss=1.2040387392044067
Iteration 128400, loss=0.5145332217216492
Iteration 128500, loss=0.5922948122024536
Iteration 128600, loss=1.1675089597702026
Iteration 128700, loss=0.5155667662620544
Iteration 128800, loss=0.5202680826187134
Iteration 128900, loss=0.9148498773574829
Iteration 129000, loss=0.608415424823761
Iteration 129100, loss=0.5744034647941589
Iteration 129200, loss=0.2212296575307846
Iteration 129300, loss=0.5301475524902344
Iteration 129400, loss=0.4996591806411743
Iteration 129500, loss=0.5159826874732971
Iteration 129600, loss=0.5502827167510986
Iteration 129700, loss=0.5750100612640381
Iteration 129800, loss=0.5902308821678162
Iteration 129900, loss=0.5305280685424805
Iteration 130000, loss=0.6944857835769653
{'p': 0.75493515, 'late': 0.75576794, 'suffered': 0.75915927, 'mayor': 0.76262504, 'j': 0.7635247, 'microsoft': 0.7652725, 'x': 0.77728873, 'one': 0.78041506, 'circa': 0.7844205, 'eight': 1.0000001}
Iteration 130100, loss=0.46062856912612915
Iteration 130200, loss=0.896649956703186
Iteration 130300, loss=0.5018301010131836
Iteration 130400, loss=0.573703944683075
Iteration 130500, loss=0.36115074157714844
Iteration 130600, loss=0.7000809907913208
Iteration 130700, loss=1.0168970823287964
Iteration 130800, loss=0.24469897150993347
Iteration 130900, loss=0.5929943323135376
Iteration 131000, loss=0.49788132309913635
Iteration 131100, loss=0.5571330189704895
Iteration 131200, loss=5.093812942504883
Iteration 131300, loss=0.4473330080509186
Iteration 131400, loss=0.5504902005195618
Iteration 131500, loss=0.518401563167572
Iteration 131600, loss=0.7680894136428833
Iteration 131700, loss=0.051419343799352646
Iteration 131800, loss=0.6454538702964783
Iteration 131900, loss=0.9467389583587646
Iteration 132000, loss=0.48280540108680725
Iteration 132100, loss=0.5207972526550293
Iteration 132200, loss=0.6578535437583923
Iteration 132300, loss=0.5242516994476318
Iteration 132400, loss=0.4394534230232239
Iteration 132500, loss=0.09894036501646042
Iteration 132600, loss=0.5404375195503235
Iteration 132700, loss=0.45488929748535156
Iteration 132800, loss=0.9158660173416138
Iteration 132900, loss=0.8680198192596436
Iteration 133000, loss=0.8745168447494507
Iteration 133100, loss=2.3540899753570557
Iteration 133200, loss=0.5836988091468811
Iteration 133300, loss=0.5587400794029236
Iteration 133400, loss=0.545589029788971
Iteration 133500, loss=0.4556714594364166
Iteration 133600, loss=0.007527264300733805
Iteration 133700, loss=0.5462145209312439
Iteration 133800, loss=0.3115488588809967
Iteration 133900, loss=0.025357168167829514
Iteration 134000, loss=0.00928463600575924
Iteration 134100, loss=1.0515358448028564
Iteration 134200, loss=0.7922724485397339
Iteration 134300, loss=1.3022685050964355
Iteration 134400, loss=0.5603812336921692
Iteration 134500, loss=0.5440446734428406
Iteration 134600, loss=0.4665588140487671
Iteration 134700, loss=1.5612767934799194
Iteration 134800, loss=0.8075156211853027
Iteration 134900, loss=0.5124964714050293
Iteration 135000, loss=0.633623480796814
Iteration 135100, loss=0.019591350108385086
Iteration 135200, loss=0.503611147403717
Iteration 135300, loss=1.7998005151748657
Iteration 135400, loss=0.8990914821624756
Iteration 135500, loss=0.6442779302597046
Iteration 135600, loss=0.5513558387756348
Iteration 135700, loss=0.8998185396194458
Iteration 135800, loss=1.4911930561065674
Iteration 135900, loss=0.5585365295410156
Iteration 136000, loss=0.14743411540985107
Iteration 136100, loss=0.5961931943893433
Iteration 136200, loss=0.5137655735015869
Iteration 136300, loss=0.03609132766723633
Iteration 136400, loss=0.7778536677360535
Iteration 136500, loss=0.48134297132492065
Iteration 136600, loss=0.058610305190086365
Iteration 136700, loss=0.6707367897033691
Iteration 136800, loss=0.7133367657661438
Iteration 136900, loss=0.7022942304611206
Iteration 137000, loss=0.5153353810310364
Iteration 137100, loss=1.055907964706421
Iteration 137200, loss=0.3992931544780731
Iteration 137300, loss=0.9478410482406616
Iteration 137400, loss=0.6912662386894226
Iteration 137500, loss=0.8004260063171387
Iteration 137600, loss=1.0670709609985352
Iteration 137700, loss=0.165972039103508
Iteration 137800, loss=0.5308791995048523
Iteration 137900, loss=0.8835704922676086
Iteration 138000, loss=0.5845046043395996
Iteration 138100, loss=0.0685485377907753
Iteration 138200, loss=0.5078173279762268
Iteration 138300, loss=0.49548807740211487
Iteration 138400, loss=0.6368520259857178
Iteration 138500, loss=0.7933213710784912
Iteration 138600, loss=0.8987597227096558
Iteration 138700, loss=0.9827044010162354
Iteration 138800, loss=0.704719603061676
Iteration 138900, loss=0.021832864731550217
Iteration 139000, loss=0.797539472579956
Iteration 139100, loss=0.9027887582778931
Iteration 139200, loss=0.572904646396637
Iteration 139300, loss=0.4416191577911377
Iteration 139400, loss=0.5918989181518555
Iteration 139500, loss=0.5066893100738525
Iteration 139600, loss=0.42733240127563477
Iteration 139700, loss=0.7007966041564941
Iteration 139800, loss=1.4176437854766846
Iteration 139900, loss=0.5364264845848083
Iteration 140000, loss=0.1114860251545906
{'taken': 0.78166604, 'defined': 0.78426945, 'note': 0.78567404, 'p': 0.7869899, 'microsoft': 0.79397607, 'j': 0.7994061, 'x': 0.80362815, 'one': 0.8126597, 'circa': 0.82144237, 'eight': 1.0000001}
Iteration 140100, loss=0.059303365647792816
Iteration 140200, loss=1.1160746812820435
Iteration 140300, loss=0.5247290134429932
Iteration 140400, loss=0.5628989934921265
Iteration 140500, loss=0.0954933911561966
Iteration 140600, loss=0.12209566682577133
Iteration 140700, loss=0.24619580805301666
Iteration 140800, loss=0.5349329113960266
Iteration 140900, loss=0.8413145542144775
Iteration 141000, loss=0.5663478970527649
Iteration 141100, loss=0.5671201348304749
Iteration 141200, loss=0.4070230722427368
Iteration 141300, loss=0.20622573792934418
Iteration 141400, loss=0.3098546266555786
Iteration 141500, loss=1.692589521408081
Iteration 141600, loss=0.7216982841491699
Iteration 141700, loss=0.4970115125179291
Iteration 141800, loss=0.3971480131149292
Iteration 141900, loss=0.5695109963417053
Iteration 142000, loss=1.0614490509033203
Iteration 142100, loss=0.45304712653160095
Iteration 142200, loss=0.5103504061698914
Iteration 142300, loss=0.6839202642440796
Iteration 142400, loss=0.5464861392974854
Iteration 142500, loss=0.1286880373954773
Iteration 142600, loss=0.26072099804878235
Iteration 142700, loss=0.20177526772022247
Iteration 142800, loss=0.13414879143238068
Iteration 142900, loss=0.8936679363250732
Iteration 143000, loss=0.6944138407707214
Iteration 143100, loss=0.4789998531341553
Iteration 143200, loss=2.277489185333252
Iteration 143300, loss=0.5213549137115479
Iteration 143400, loss=0.5406243801116943
Iteration 143500, loss=0.5123820900917053
Iteration 143600, loss=0.5876708626747131
Iteration 143700, loss=0.5542857050895691
Iteration 143800, loss=0.5055997371673584
Iteration 143900, loss=0.5232319235801697
Iteration 144000, loss=0.5339107513427734
Iteration 144100, loss=0.4661453366279602
Iteration 144200, loss=0.43868380784988403
Iteration 144300, loss=0.5690996646881104
Iteration 144400, loss=0.6791930794715881
Iteration 144500, loss=0.9330156445503235
Iteration 144600, loss=0.4953295886516571
Iteration 144700, loss=0.10936807096004486
Iteration 144800, loss=0.6652980446815491
Iteration 144900, loss=0.5579052567481995
Iteration 145000, loss=0.8064596056938171
Iteration 145100, loss=0.12314876914024353
Iteration 145200, loss=0.6499931216239929
Iteration 145300, loss=0.7881426215171814
Iteration 145400, loss=0.7204841375350952
Iteration 145500, loss=0.026448920369148254
Iteration 145600, loss=1.041536808013916
Iteration 145700, loss=0.3810632526874542
Iteration 145800, loss=1.509749174118042
Iteration 145900, loss=0.4786451756954193
Iteration 146000, loss=0.45167988538742065
Iteration 146100, loss=0.5170758366584778
Iteration 146200, loss=0.6539117693901062
Iteration 146300, loss=0.4991784691810608
Iteration 146400, loss=0.4015129506587982
Iteration 146500, loss=0.6487166285514832
Iteration 146600, loss=0.4905185401439667
Iteration 146700, loss=0.3884868025779724
Iteration 146800, loss=1.0922229290008545
Iteration 146900, loss=0.49931901693344116
Iteration 147000, loss=0.21934202313423157
Iteration 147100, loss=0.38518258929252625
Iteration 147200, loss=0.5359596014022827
Iteration 147300, loss=0.16508854925632477
Iteration 147400, loss=0.4309075176715851
Iteration 147500, loss=0.5217228531837463
Iteration 147600, loss=0.6016230583190918
Iteration 147700, loss=0.5348538160324097
Iteration 147800, loss=0.9193263053894043
Iteration 147900, loss=0.5355290770530701
Iteration 148000, loss=0.5244684815406799
Iteration 148100, loss=0.017415419220924377
Iteration 148200, loss=0.5291351675987244
Iteration 148300, loss=0.5050203800201416
Iteration 148400, loss=0.4943433701992035
Iteration 148500, loss=0.615959644317627
Iteration 148600, loss=0.16349558532238007
Iteration 148700, loss=0.5643839240074158
Iteration 148800, loss=0.5236051082611084
Iteration 148900, loss=0.5014141201972961
Iteration 149000, loss=0.6266172528266907
Iteration 149100, loss=0.4232141971588135
Iteration 149200, loss=0.43507927656173706
Iteration 149300, loss=0.5362829566001892
Iteration 149400, loss=0.694939911365509
Iteration 149500, loss=0.5681065320968628
Iteration 149600, loss=0.002028721384704113
Iteration 149700, loss=0.4947746694087982
Iteration 149800, loss=0.5367684960365295
Iteration 149900, loss=0.5136287212371826
Iteration 150000, loss=0.48000267148017883
{'zero': 0.8091839, 'x': 0.8108, 'microsoft': 0.8154116, 'taken': 0.81767255, 'defined': 0.8201665, 'j': 0.82190794, 'sold': 0.8235769, 'one': 0.83647794, 'circa': 0.8579462, 'eight': 1.0000001}
Iteration 150100, loss=0.44218793511390686
Iteration 150200, loss=0.5423800945281982
Iteration 150300, loss=0.5006047487258911
Iteration 150400, loss=0.49972259998321533
Iteration 150500, loss=0.4147240221500397
Iteration 150600, loss=0.5009227395057678
Iteration 150700, loss=0.8509954214096069
Iteration 150800, loss=0.600697934627533
Iteration 150900, loss=0.9130798578262329
Iteration 151000, loss=0.5368999242782593
Iteration 151100, loss=0.5299293398857117
Iteration 151200, loss=0.5309361815452576
Iteration 151300, loss=0.5126126408576965
Iteration 151400, loss=0.2759656310081482
Iteration 151500, loss=0.5134570002555847
Iteration 151600, loss=0.7691110372543335
Iteration 151700, loss=0.9071564078330994
Iteration 151800, loss=0.4614105224609375
Iteration 151900, loss=0.293561726808548
Iteration 152000, loss=0.7609400749206543
Iteration 152100, loss=0.3806529641151428
Iteration 152200, loss=0.9184494614601135
Iteration 152300, loss=0.5030901432037354
Iteration 152400, loss=0.7484875917434692
Iteration 152500, loss=0.5301206707954407
Iteration 152600, loss=0.8830715417861938
Iteration 152700, loss=0.6564339399337769
Iteration 152800, loss=0.8840397596359253
Iteration 152900, loss=0.5858814120292664
Iteration 153000, loss=0.7218875885009766
Iteration 153100, loss=0.4929058849811554
Iteration 153200, loss=0.4863848090171814
Iteration 153300, loss=0.5303937792778015
Iteration 153400, loss=0.5541698932647705
Iteration 153500, loss=0.48917099833488464
Iteration 153600, loss=1.0297763347625732
Iteration 153700, loss=0.5373938083648682
Iteration 153800, loss=0.4985072612762451
Iteration 153900, loss=0.5441917777061462
Iteration 154000, loss=0.7182161211967468
Iteration 154100, loss=0.7669951915740967
Iteration 154200, loss=0.6155083179473877
Iteration 154300, loss=0.8259563446044922
Iteration 154400, loss=0.7304224967956543
Iteration 154500, loss=0.5972532033920288
Iteration 154600, loss=0.5991270542144775
Iteration 154700, loss=0.4907601475715637
Iteration 154800, loss=0.7541338205337524
Iteration 154900, loss=0.11633827537298203
Iteration 155000, loss=0.5097809433937073
Iteration 155100, loss=0.02961900644004345
Iteration 155200, loss=0.23094041645526886
Iteration 155300, loss=0.5233743786811829
Iteration 155400, loss=0.8593879342079163
Iteration 155500, loss=0.09031006693840027
Iteration 155600, loss=0.4962792992591858
Iteration 155700, loss=0.9309089779853821
Iteration 155800, loss=0.7968077063560486
Iteration 155900, loss=0.03151783347129822
Iteration 156000, loss=0.861236035823822
Iteration 156100, loss=0.7527545690536499
Iteration 156200, loss=0.3800755739212036
Iteration 156300, loss=0.5544195771217346
Iteration 156400, loss=0.5299660563468933
Iteration 156500, loss=0.05654020980000496
Iteration 156600, loss=0.3988248407840729
Iteration 156700, loss=0.5295549035072327
Iteration 156800, loss=3.1463162741829365e-08
Iteration 156900, loss=0.6760252714157104
Iteration 157000, loss=1.1998937129974365
Iteration 157100, loss=1.2775481939315796
Iteration 157200, loss=0.4804970622062683
Iteration 157300, loss=0.5288588404655457
Iteration 157400, loss=0.6456080079078674
Iteration 157500, loss=0.5693507194519043
Iteration 157600, loss=0.3205789029598236
Iteration 157700, loss=0.7414059638977051
Iteration 157800, loss=0.5153306722640991
Iteration 157900, loss=0.8547376394271851
Iteration 158000, loss=0.20423564314842224
Iteration 158100, loss=0.5103796124458313
Iteration 158200, loss=0.3407629430294037
Iteration 158300, loss=1.134137749671936
Iteration 158400, loss=0.8424345254898071
Iteration 158500, loss=0.9002280235290527
Iteration 158600, loss=0.685722291469574
Iteration 158700, loss=0.2585730254650116
Iteration 158800, loss=0.5140709280967712
Iteration 158900, loss=0.8377490043640137
Iteration 159000, loss=0.5588594079017639
Iteration 159100, loss=0.8054594397544861
Iteration 159200, loss=0.09097175300121307
Iteration 159300, loss=0.06810479611158371
Iteration 159400, loss=0.5637037754058838
Iteration 159500, loss=0.05898530036211014
Iteration 159600, loss=0.5232065320014954
Iteration 159700, loss=0.5058395862579346
Iteration 159800, loss=0.5252062082290649
Iteration 159900, loss=0.3089044988155365
Iteration 160000, loss=0.22229218482971191
{'mid': 0.82263935, 'm': 0.82298726, 'admiral': 0.82408494, 'zero': 0.830351, 'j': 0.83233166, 'microsoft': 0.83394367, 'defined': 0.8390898, 'circa': 0.8470181, 'one': 0.8560752, 'eight': 1.0000001}
Iteration 160100, loss=0.7470954656600952
Iteration 160200, loss=0.5222081542015076
Iteration 160300, loss=0.6932573318481445
Iteration 160400, loss=0.7369948625564575
Iteration 160500, loss=0.5346674919128418
Iteration 160600, loss=0.5342743992805481
Iteration 160700, loss=0.5468173623085022
Iteration 160800, loss=0.4508596956729889
Iteration 160900, loss=0.4361889064311981
Iteration 161000, loss=1.215830683708191
Iteration 161100, loss=0.5055961012840271
Iteration 161200, loss=0.3247227966785431
Iteration 161300, loss=0.45981162786483765
Iteration 161400, loss=0.924484372138977
Iteration 161500, loss=0.6052061915397644
Iteration 161600, loss=0.5313441753387451
Iteration 161700, loss=0.5286537408828735
Iteration 161800, loss=0.4696424603462219
Iteration 161900, loss=0.49941253662109375
Iteration 162000, loss=0.5285844802856445
Iteration 162100, loss=0.5591919422149658
Iteration 162200, loss=0.45397740602493286
Iteration 162300, loss=0.21008074283599854
Iteration 162400, loss=0.5033307671546936
Iteration 162500, loss=0.9187108278274536
Iteration 162600, loss=0.5201651453971863
Iteration 162700, loss=0.9604052901268005
Iteration 162800, loss=0.5049137473106384
Iteration 162900, loss=0.6343174576759338
Iteration 163000, loss=0.8725101947784424
Iteration 163100, loss=0.49990659952163696
Iteration 163200, loss=0.5091685652732849
Iteration 163300, loss=0.350555956363678
Iteration 163400, loss=0.4723980724811554
Iteration 163500, loss=0.7956340312957764
Iteration 163600, loss=0.5975468158721924
Iteration 163700, loss=0.6148994565010071
Iteration 163800, loss=0.5162325501441956
Iteration 163900, loss=0.5413882732391357
Iteration 164000, loss=0.49168065190315247
Iteration 164100, loss=0.07149277627468109
Iteration 164200, loss=0.5558705925941467
Iteration 164300, loss=0.3210422992706299
Iteration 164400, loss=0.8388085961341858
Iteration 164500, loss=0.5141443014144897
Iteration 164600, loss=0.5215967893600464
Iteration 164700, loss=0.5569049715995789
Iteration 164800, loss=0.6099629402160645
Iteration 164900, loss=0.3864613473415375
Iteration 165000, loss=0.009145117364823818
Iteration 165100, loss=0.29335781931877136
Iteration 165200, loss=0.5850468873977661
Iteration 165300, loss=0.4642707109451294
Iteration 165400, loss=1.0234627723693848
Iteration 165500, loss=1.1958177089691162
Iteration 165600, loss=0.5257046222686768
Iteration 165700, loss=1.114747166633606
Iteration 165800, loss=0.7052119374275208
Iteration 165900, loss=0.6407417058944702
Iteration 166000, loss=0.906366229057312
Iteration 166100, loss=0.04078211262822151
Iteration 166200, loss=0.00236899103038013
Iteration 166300, loss=0.4564180076122284
Iteration 166400, loss=0.5242676138877869
Iteration 166500, loss=0.9141110181808472
Iteration 166600, loss=0.8222104907035828
Iteration 166700, loss=0.5253122448921204
Iteration 166800, loss=9.261545528715942e-06
Iteration 166900, loss=0.4909696877002716
Iteration 167000, loss=0.5433125495910645
Iteration 167100, loss=0.879547119140625
Iteration 167200, loss=0.524841845035553
Iteration 167300, loss=0.8891069293022156
Iteration 167400, loss=0.49182119965553284
Iteration 167500, loss=0.4065147340297699
Iteration 167600, loss=0.4672393500804901
Iteration 167700, loss=0.04615361616015434
Iteration 167800, loss=0.487591415643692
Iteration 167900, loss=0.5463401675224304
Iteration 168000, loss=0.9094558954238892
Iteration 168100, loss=0.7115877866744995
Iteration 168200, loss=0.9396399855613708
Iteration 168300, loss=0.8652606010437012
Iteration 168400, loss=0.6538587212562561
Iteration 168500, loss=0.6491488218307495
Iteration 168600, loss=0.5905434489250183
Iteration 168700, loss=0.4130995571613312
Iteration 168800, loss=0.5513227581977844
Iteration 168900, loss=0.8722834587097168
Iteration 169000, loss=0.6368644833564758
Iteration 169100, loss=0.5547053217887878
Iteration 169200, loss=0.9776852130889893
Iteration 169300, loss=0.5286849737167358
Iteration 169400, loss=0.07238586992025375
Iteration 169500, loss=0.5925995111465454
Iteration 169600, loss=0.5588392615318298
Iteration 169700, loss=0.6638954281806946
Iteration 169800, loss=0.057571832090616226
Iteration 169900, loss=1.1876615285873413
Iteration 170000, loss=0.23775915801525116
{'drake': 0.8339033, 'zero': 0.8343891, 'three': 0.8344877, 'microsoft': 0.83602697, 'm': 0.8368086, 's': 0.84016335, 'circa': 0.84501386, 'j': 0.84712946, 'one': 0.86071, 'eight': 1.0}
Iteration 170100, loss=0.8621770143508911
Iteration 170200, loss=0.6041191220283508
Iteration 170300, loss=0.720471978187561
Iteration 170400, loss=0.7229479551315308
Iteration 170500, loss=0.0796147957444191
Iteration 170600, loss=0.6406865119934082
Iteration 170700, loss=0.7645405530929565
Iteration 170800, loss=0.11279941350221634
Iteration 170900, loss=0.5216830372810364
Iteration 171000, loss=0.566364049911499
Iteration 171100, loss=0.8754938244819641
Iteration 171200, loss=0.5788479447364807
Iteration 171300, loss=0.579353928565979
Iteration 171400, loss=0.3321785032749176
Iteration 171500, loss=0.38541555404663086
Iteration 171600, loss=0.6672228574752808
Iteration 171700, loss=0.6336875557899475
Iteration 171800, loss=0.28076374530792236
Iteration 171900, loss=1.0149056911468506
Iteration 172000, loss=0.3119811713695526
Iteration 172100, loss=0.6542680263519287
Iteration 172200, loss=0.5264927744865417
Iteration 172300, loss=0.511726975440979
Iteration 172400, loss=0.34001368284225464
Iteration 172500, loss=0.2781311869621277
Iteration 172600, loss=0.5213444232940674
Iteration 172700, loss=0.48169830441474915
Iteration 172800, loss=0.5342644453048706
Iteration 172900, loss=0.02676316909492016
Iteration 173000, loss=0.475576788187027
Iteration 173100, loss=0.9720871448516846
Iteration 173200, loss=0.9385778903961182
Iteration 173300, loss=0.3981160819530487
Iteration 173400, loss=0.017630113288760185
Iteration 173500, loss=0.5274757146835327
Iteration 173600, loss=0.5336836576461792
Iteration 173700, loss=0.5371779203414917
Iteration 173800, loss=0.5336740612983704
Iteration 173900, loss=0.5343364477157593
Iteration 174000, loss=0.6646128296852112
Iteration 174100, loss=1.121633529663086
Iteration 174200, loss=0.9996657371520996
Iteration 174300, loss=0.5524982213973999
Iteration 174400, loss=0.046306952834129333
Iteration 174500, loss=0.9254497289657593
Iteration 174600, loss=0.6745519042015076
Iteration 174700, loss=0.5007946491241455
Iteration 174800, loss=0.6810594797134399
Iteration 174900, loss=0.4637623727321625
Iteration 175000, loss=0.8200227618217468
Iteration 175100, loss=0.49141615629196167
Iteration 175200, loss=2.9171741008758545
Iteration 175300, loss=0.3666031062602997
Iteration 175400, loss=0.3175854980945587
Iteration 175500, loss=0.12993164360523224
Iteration 175600, loss=0.6394716501235962
Iteration 175700, loss=0.0007731093792244792
Iteration 175800, loss=0.5216371417045593
Iteration 175900, loss=0.5099404454231262
Iteration 176000, loss=0.5282561182975769
Iteration 176100, loss=1.0946907997131348
Iteration 176200, loss=0.6311392188072205
Iteration 176300, loss=0.4443136155605316
Iteration 176400, loss=0.9025801420211792
Iteration 176500, loss=1.0209579467773438
Iteration 176600, loss=0.5155959129333496
Iteration 176700, loss=0.897568941116333
Iteration 176800, loss=0.5214579701423645
Iteration 176900, loss=0.1553545892238617
Iteration 177000, loss=0.7022071480751038
Iteration 177100, loss=0.25968465209007263
Iteration 177200, loss=0.06111227348446846
Iteration 177300, loss=0.9400384426116943
Iteration 177400, loss=0.6377968192100525
Iteration 177500, loss=0.6540760397911072
Iteration 177600, loss=0.053562916815280914
Iteration 177700, loss=0.6762206554412842
Iteration 177800, loss=0.5236888527870178
Iteration 177900, loss=0.5051122307777405
Iteration 178000, loss=0.2045915722846985
Iteration 178100, loss=0.8974106311798096
Iteration 178200, loss=0.6108043789863586
Iteration 178300, loss=0.00127130257897079
Iteration 178400, loss=0.04000478982925415
Iteration 178500, loss=0.4856012165546417
Iteration 178600, loss=1.4479788541793823
Iteration 178700, loss=1.0069220066070557
Iteration 178800, loss=0.4982295632362366
Iteration 178900, loss=1.633484125137329
Iteration 179000, loss=0.46999236941337585
Iteration 179100, loss=0.751026451587677
Iteration 179200, loss=0.8881810903549194
Iteration 179300, loss=0.5005013942718506
Iteration 179400, loss=0.5541803240776062
Iteration 179500, loss=0.5199175477027893
Iteration 179600, loss=0.3619180917739868
Iteration 179700, loss=0.49406421184539795
Iteration 179800, loss=0.4621898829936981
Iteration 179900, loss=0.4134047031402588
Iteration 180000, loss=0.5370519757270813
{'november': 0.84517777, 'zero': 0.84672874, 'nine': 0.85324454, 'three': 0.8534972, 'j': 0.8538159, 'circa': 0.859352, 'm': 0.8632508, 'year': 0.86457825, 'one': 0.8874795, 'eight': 1.0}
Iteration 180100, loss=0.11490623652935028
Iteration 180200, loss=1.5681477785110474
Iteration 180300, loss=0.45079442858695984
Iteration 180400, loss=0.6566364765167236
Iteration 180500, loss=0.5451021194458008
Iteration 180600, loss=0.765379011631012
Iteration 180700, loss=0.596486508846283
Iteration 180800, loss=0.528683602809906
Iteration 180900, loss=0.6948337554931641
Iteration 181000, loss=0.7457484006881714
Iteration 181100, loss=0.5114483833312988
Iteration 181200, loss=0.6229677796363831
Iteration 181300, loss=0.595592737197876
Iteration 181400, loss=0.4553947448730469
Iteration 181500, loss=0.3758217394351959
Iteration 181600, loss=0.570583164691925
Iteration 181700, loss=0.40808427333831787
Iteration 181800, loss=0.5426853895187378
Iteration 181900, loss=0.8654805421829224
Iteration 182000, loss=0.5495439767837524
Iteration 182100, loss=0.5322885513305664
Iteration 182200, loss=0.005057354923337698
Iteration 182300, loss=1.8110260963439941
Iteration 182400, loss=0.2637963891029358
Iteration 182500, loss=0.5476843118667603
Iteration 182600, loss=0.9711292386054993
Iteration 182700, loss=0.017941631376743317
Iteration 182800, loss=0.5199589133262634
Iteration 182900, loss=0.5487746596336365
Iteration 183000, loss=0.5251098871231079
Iteration 183100, loss=0.8695452809333801
Iteration 183200, loss=0.5165599584579468
Iteration 183300, loss=0.5469376444816589
Iteration 183400, loss=0.9252029657363892
Iteration 183500, loss=0.5877936482429504
Iteration 183600, loss=0.17374365031719208
Iteration 183700, loss=0.7245382070541382
Iteration 183800, loss=0.5034206509590149
Iteration 183900, loss=0.006074210628867149
Iteration 184000, loss=0.00745010282844305
Iteration 184100, loss=0.6791766881942749
Iteration 184200, loss=0.545651376247406
Iteration 184300, loss=0.7974865436553955
Iteration 184400, loss=0.8823273181915283
Iteration 184500, loss=0.6039286255836487
Iteration 184600, loss=0.9453647136688232
Iteration 184700, loss=1.0010805130004883
Iteration 184800, loss=0.9676696062088013
Iteration 184900, loss=0.8398030996322632
Iteration 185000, loss=0.42929115891456604
Iteration 185100, loss=1.1902271509170532
Iteration 185200, loss=0.8512558937072754
Iteration 185300, loss=0.5448101162910461
Iteration 185400, loss=0.5452303886413574
Iteration 185500, loss=0.9522948265075684
Iteration 185600, loss=0.866284966468811
Iteration 185700, loss=2.3395800590515137
Iteration 185800, loss=0.842170238494873
Iteration 185900, loss=0.8164829015731812
Iteration 186000, loss=5.341704536476755e-07
Iteration 186100, loss=0.04272567853331566
Iteration 186200, loss=0.9091886281967163
Iteration 186300, loss=0.013238896615803242
Iteration 186400, loss=0.5068578124046326
Iteration 186500, loss=0.6255632638931274
Iteration 186600, loss=0.4914171099662781
Iteration 186700, loss=0.4012024700641632
Iteration 186800, loss=0.7935678362846375
Iteration 186900, loss=0.8792188167572021
Iteration 187000, loss=0.9260482788085938
Iteration 187100, loss=0.720018744468689
Iteration 187200, loss=0.5204084515571594
Iteration 187300, loss=0.7501168251037598
Iteration 187400, loss=0.34726810455322266
Iteration 187500, loss=0.5931009650230408
Iteration 187600, loss=0.5565236210823059
Iteration 187700, loss=0.47091272473335266
Iteration 187800, loss=0.3026561737060547
Iteration 187900, loss=0.015843847766518593
Iteration 188000, loss=0.7398920655250549
Iteration 188100, loss=0.8620650768280029
Iteration 188200, loss=0.04639773070812225
Iteration 188300, loss=0.5290706753730774
Iteration 188400, loss=0.34691500663757324
Iteration 188500, loss=0.5942462086677551
Iteration 188600, loss=0.31417223811149597
Iteration 188700, loss=0.5335210561752319
Iteration 188800, loss=0.9720920920372009
Iteration 188900, loss=0.8464429974555969
Iteration 189000, loss=0.5308797359466553
Iteration 189100, loss=0.5415264964103699
Iteration 189200, loss=0.4928371012210846
Iteration 189300, loss=0.8098767995834351
Iteration 189400, loss=0.033895038068294525
Iteration 189500, loss=0.5183082818984985
Iteration 189600, loss=0.3108546733856201
Iteration 189700, loss=0.07514893263578415
Iteration 189800, loss=0.16654212772846222
Iteration 189900, loss=0.8161066174507141
Iteration 190000, loss=1.2283668518066406
{'two': 0.84240484, 'drake': 0.84309506, 'zero': 0.846987, 'nine': 0.85187024, 'circa': 0.8543262, 'year': 0.8545292, 'm': 0.8622712, 'three': 0.87067586, 'one': 0.87790954, 'eight': 1.0000001}
Iteration 190100, loss=0.11195796728134155
Iteration 190200, loss=0.9744599461555481
Iteration 190300, loss=0.6577326059341431
Iteration 190400, loss=0.5112655162811279
Iteration 190500, loss=0.5455115437507629
Iteration 190600, loss=0.7064142227172852
Iteration 190700, loss=0.8632980585098267
Iteration 190800, loss=0.9155585765838623
Iteration 190900, loss=0.7283132076263428
Iteration 191000, loss=0.7788527011871338
Iteration 191100, loss=0.5661781430244446
Iteration 191200, loss=0.5277142524719238
Iteration 191300, loss=0.8988414406776428
Iteration 191400, loss=0.6507508754730225
Iteration 191500, loss=0.8867913484573364
Iteration 191600, loss=0.4986629784107208
Iteration 191700, loss=0.9320472478866577
Iteration 191800, loss=0.538520336151123
Iteration 191900, loss=1.3261305093765259
Iteration 192000, loss=0.4052431881427765
Iteration 192100, loss=0.5194548964500427
Iteration 192200, loss=1.0277268886566162
Iteration 192300, loss=0.01508281473070383
Iteration 192400, loss=0.5205557942390442
Iteration 192500, loss=0.5619451403617859
Iteration 192600, loss=0.9635787010192871
Iteration 192700, loss=0.23035822808742523
Iteration 192800, loss=0.2618018388748169
Iteration 192900, loss=0.5062164664268494
Iteration 193000, loss=0.43613120913505554
Iteration 193100, loss=0.5144481062889099
Iteration 193200, loss=0.5451233983039856
Iteration 193300, loss=0.7830100059509277
Iteration 193400, loss=0.5163161754608154
Iteration 193500, loss=0.10160863399505615
Iteration 193600, loss=0.5011948347091675
Iteration 193700, loss=0.4868880808353424
Iteration 193800, loss=0.557034432888031
Iteration 193900, loss=1.3241690397262573
Iteration 194000, loss=0.5109381079673767
Iteration 194100, loss=0.9684340953826904
Iteration 194200, loss=0.5099160075187683
Iteration 194300, loss=0.5148060917854309
Iteration 194400, loss=0.918326735496521
Iteration 194500, loss=0.9135887026786804
Iteration 194600, loss=0.6673116683959961
Iteration 194700, loss=0.5291422605514526
Iteration 194800, loss=0.49600648880004883
Iteration 194900, loss=0.5529650449752808
Iteration 195000, loss=0.520865261554718
Iteration 195100, loss=1.0450938940048218
Iteration 195200, loss=0.650390625
Iteration 195300, loss=0.9078773260116577
Iteration 195400, loss=0.8493166565895081
Iteration 195500, loss=0.009434381499886513
Iteration 195600, loss=0.5224760174751282
Iteration 195700, loss=0.9123120903968811
Iteration 195800, loss=0.5354456901550293
Iteration 195900, loss=0.5679400563240051
Iteration 196000, loss=0.8679541349411011
Iteration 196100, loss=0.010958398692309856
Iteration 196200, loss=0.7109769582748413
Iteration 196300, loss=0.8594621419906616
Iteration 196400, loss=0.5847893357276917
Iteration 196500, loss=0.5448948740959167
Iteration 196600, loss=0.719352662563324
Iteration 196700, loss=0.6221957802772522
Iteration 196800, loss=0.0038519029039889574
Iteration 196900, loss=0.5244441032409668
Iteration 197000, loss=0.41254469752311707
Iteration 197100, loss=0.9160990715026855
Iteration 197200, loss=0.733788251876831
Iteration 197300, loss=0.39606595039367676
Iteration 197400, loss=0.7819589376449585
Iteration 197500, loss=0.6872284412384033
Iteration 197600, loss=0.030601028352975845
Iteration 197700, loss=0.0017052004113793373
Iteration 197800, loss=0.5095219016075134
Iteration 197900, loss=0.35101118683815
Iteration 198000, loss=1.0019975900650024
Iteration 198100, loss=0.5054132342338562
Iteration 198200, loss=0.9244054555892944
Iteration 198300, loss=0.5292015075683594
Iteration 198400, loss=0.45628079771995544
Iteration 198500, loss=0.057129085063934326
Iteration 198600, loss=0.11132099479436874
Iteration 198700, loss=0.07458712160587311
Iteration 198800, loss=0.9079060554504395
Iteration 198900, loss=0.6790964007377625
Iteration 199000, loss=0.743498682975769
Iteration 199100, loss=0.4839840829372406
Iteration 199200, loss=0.5314618349075317
Iteration 199300, loss=4.227583121974021e-05
Iteration 199400, loss=0.4411240220069885
Iteration 199500, loss=0.29556724429130554
Iteration 199600, loss=0.5438578724861145
Iteration 199700, loss=0.5115063190460205
Iteration 199800, loss=0.5956586599349976
Iteration 199900, loss=3.9932606341608334e-06